{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Recipes: Chapter 5: GroupBys and Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupBy allows you to group rows together based off some column value. groupby() is an alias for groupBy(), and we have use them interchangeably so do not get confuse. While the methods are case sensitive, aliases of the methods when available, help you focus not on the upperCase or lowerCase of the letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45222\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# creating a SparkSession object - you can change any of the configuration option you like. Remember this would\n",
    "# get the existsing SparkSession and would not create a new one.\n",
    "# So in case your previous notebook is still running - no issues\n",
    "sparkSession = SparkSession \\\n",
    "                .builder \\\n",
    "                .master(\"local\") \\\n",
    "                .appName(\"Pyspark Recipes - Importing Data\") \\\n",
    "                .getOrCreate()\n",
    "\n",
    "# Importing the data which we would use in our project\n",
    "dfCensus = sparkSession.read.format('csv') \\\n",
    "            .options(header = True, inferSchema = True, sep = \",\", enforceSchema = True,\n",
    "                ignoreLeadingWhiteSpace = True, ignoreTrailingWhiteSpace = True) \\\n",
    "            .load('../datasets/charityml/censusdata.csv')\n",
    "\n",
    "print(dfCensus.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+---------------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "|age|       workclass|education_level|education-num|    marital-status|       occupation| relationship| race|   sex|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+----------------+---------------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "| 39|       State-gov|      Bachelors|         13.0|     Never-married|     Adm-clerical|Not-in-family|White|  Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
      "| 50|Self-emp-not-inc|      Bachelors|         13.0|Married-civ-spouse|  Exec-managerial|      Husband|White|  Male|         0.0|         0.0|          13.0| United-States| <=50K|\n",
      "| 38|         Private|        HS-grad|          9.0|          Divorced|Handlers-cleaners|Not-in-family|White|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "| 53|         Private|           11th|          7.0|Married-civ-spouse|Handlers-cleaners|      Husband|Black|  Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "| 28|         Private|      Bachelors|         13.0|Married-civ-spouse|   Prof-specialty|         Wife|Black|Female|         0.0|         0.0|          40.0|          Cuba| <=50K|\n",
      "+---+----------------+---------------+-------------+------------------+-----------------+-------------+-----+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCensus.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      marital-status|count|\n",
      "+--------------------+-----+\n",
      "|           Separated| 1411|\n",
      "|       Never-married|14598|\n",
      "|Married-spouse-ab...|  552|\n",
      "|            Divorced| 6297|\n",
      "|             Widowed| 1277|\n",
      "|   Married-AF-spouse|   32|\n",
      "|  Married-civ-spouse|21055|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCensus.groupBy(\"marital-status\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be deconstructing the above sequence of steps to understand the mechanism happening behind the screen.\n",
    "\n",
    "When you use the \"groupby\" method on a dataframe, the returning result is a GroupedData Object and not a dataframe. A GroupedData object is a transitional object, where the object is waiting for instruction on how to summarize the information contained in each group. \n",
    "\n",
    "Try doing a show on the following code and check the error for yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objGroupByMaritalStatus = dfCensus.groupBy(\"marital-status\")\n",
    "objGroupByMaritalStatus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above line of code would return an error, the following functions are completely valid: sum(), mean(), min(), max(), count(), avg(). It takes a column name in the object other than the one that is grouped by which are \"non-string\". \n",
    "\n",
    "Try calling one of the methods on the GroupedData obect, and see the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[marital-status: string, max(age): int, max(education-num): double, max(capital-gain): double, max(capital-loss): double, max(hours-per-week): double]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objGroupByMaritalStatus.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use a \"count()\" method (but there is no show() method) on the object, we get a dataframe back containing the grouping column, in this case \"marital-status\". The resulting dataframe would contain only two columns, one on which was used for groupBy to create the GroupedData Object (\"marital-status\"), and the other on which the any of the aggregation operation was performed. \n",
    "\n",
    "No other \"string\" columns in the dataframe - dfCensus in this case - would be available, unless and until, they are used for a groupBy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      marital-status|count|\n",
      "+--------------------+-----+\n",
      "|           Separated| 1411|\n",
      "|       Never-married|14598|\n",
      "|Married-spouse-ab...|  552|\n",
      "|            Divorced| 6297|\n",
      "|             Widowed| 1277|\n",
      "|   Married-AF-spouse|   32|\n",
      "|  Married-civ-spouse|21055|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfGroupedByMaritalStatus = objGroupByMaritalStatus.count()\n",
    "dfGroupedByMaritalStatus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above code produced a \"count\" column, where have count of rows of the GroupedData objects, if you use any of the other aggregation functions - min, max, avg, sum, mean - unless and until you specify the column names, the method would be applied to all the non-string columns to the dataframe from which the GroupedData object was created, in our case dfCensus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------------------+-----------------+-----------------+-------------------+\n",
      "|      marital-status|max(age)|max(education-num)|max(capital-gain)|max(capital-loss)|max(hours-per-week)|\n",
      "+--------------------+--------+------------------+-----------------+-----------------+-------------------+\n",
      "|           Separated|      90|              16.0|          99999.0|           3900.0|               99.0|\n",
      "|       Never-married|      90|              16.0|          99999.0|           3770.0|               99.0|\n",
      "|Married-spouse-ab...|      87|              16.0|          99999.0|           3004.0|               99.0|\n",
      "|            Divorced|      90|              16.0|          99999.0|           3900.0|               99.0|\n",
      "|             Widowed|      90|              16.0|          99999.0|           4356.0|               99.0|\n",
      "|   Married-AF-spouse|      58|              16.0|          99999.0|           1485.0|               90.0|\n",
      "|  Married-civ-spouse|      90|              16.0|          99999.0|           2603.0|               99.0|\n",
      "+--------------------+--------+------------------+-----------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfGroupedByMaritalStatus = objGroupByMaritalStatus.max()\n",
    "dfGroupedByMaritalStatus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----------------+\n",
      "|      marital-status|max(education-num)|max(capital-gain)|\n",
      "+--------------------+------------------+-----------------+\n",
      "|           Separated|              16.0|          99999.0|\n",
      "|       Never-married|              16.0|          99999.0|\n",
      "|Married-spouse-ab...|              16.0|          99999.0|\n",
      "|            Divorced|              16.0|          99999.0|\n",
      "|             Widowed|              16.0|          99999.0|\n",
      "|   Married-AF-spouse|              16.0|          99999.0|\n",
      "|  Married-civ-spouse|              16.0|          99999.0|\n",
      "+--------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfGroupedByMaritalStatus = objGroupByMaritalStatus.max(\"education-num\", \"capital-gain\")\n",
    "dfGroupedByMaritalStatus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing the \"agg\" method. The generic \"agg\" method would call the aggregate across all rows in the dataframe column specified. It can take in arguments as a single column, or create multiple aggregation calls all at once using dictionary notaion, which we will see in a short while. \n",
    "\n",
    "The benefit of \"agg\" method, is that we can calculate many aggregations at a time on a single statement using Spark SQL aggregate functions sum(), avg(), min(), max() mean(), as you would see in a little while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|      marital-status|count(marital-status)|\n",
      "+--------------------+---------------------+\n",
      "|           Separated|                 1411|\n",
      "|       Never-married|                14598|\n",
      "|Married-spouse-ab...|                  552|\n",
      "|            Divorced|                 6297|\n",
      "|             Widowed|                 1277|\n",
      "|   Married-AF-spouse|                   32|\n",
      "|  Married-civ-spouse|                21055|\n",
      "+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCensus.groupby('marital-status').agg({'marital-status': 'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call the \"agg\" method as a generic one, it can be applied to a dataframe without a \"groupBy\". Say for some reason you want to have a average of capital gain for the entire dataframe.\n",
    "\n",
    "Not much useful, as mean, max, average are available in the describe() method, that we have seen in chapter 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| avg(capital-gain)|\n",
      "+------------------+\n",
      "|1101.4303436380524|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCensus.agg({'capital-gain': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+-----------------+\n",
      "|      marital-status|education_level|count(income)|max(capital-gain)|\n",
      "+--------------------+---------------+-------------+-----------------+\n",
      "|             Widowed|   Some-college|          218|          15831.0|\n",
      "|Married-spouse-ab...|   Some-college|          101|          27828.0|\n",
      "|            Divorced|      Assoc-voc|          349|          15831.0|\n",
      "|            Divorced|           11th|          172|          14084.0|\n",
      "|            Divorced|           10th|          152|          14344.0|\n",
      "|       Never-married|           10th|          438|          34095.0|\n",
      "|  Married-civ-spouse|     Assoc-acdm|          665|          20051.0|\n",
      "|           Separated|      Doctorate|           11|          14084.0|\n",
      "|             Widowed|            9th|           28|           2062.0|\n",
      "|            Divorced|        7th-8th|           84|           2964.0|\n",
      "|           Separated|      Bachelors|          129|          99999.0|\n",
      "|             Widowed|      Assoc-voc|           48|          25124.0|\n",
      "|             Widowed|           10th|           61|           2538.0|\n",
      "|             Widowed|      Doctorate|           12|          25124.0|\n",
      "|  Married-civ-spouse|      Preschool|           24|          41310.0|\n",
      "|           Separated|      Assoc-voc|           60|           6723.0|\n",
      "|Married-spouse-ab...|      Doctorate|            9|          27828.0|\n",
      "|            Divorced|      Preschool|            2|              0.0|\n",
      "|  Married-civ-spouse|        Masters|         1438|          99999.0|\n",
      "|           Separated|     Assoc-acdm|           41|          25236.0|\n",
      "+--------------------+---------------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCensus.groupby('marital-status','education_level').agg({'income': 'count', 'capital-gain': 'max'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had mentioned that the \"agg\" method accepts dictionary, so that you can specificy multiple columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----------------+------------------+-------------------+------------------+\n",
      "|      marital-status|education_level|sum(capital-loss)|max(education-num)|min(hours-per-week)| avg(capital-gain)|\n",
      "+--------------------+---------------+-----------------+------------------+-------------------+------------------+\n",
      "|             Widowed|   Some-college|          12312.0|              10.0|                1.0| 350.8256880733945|\n",
      "|Married-spouse-ab...|   Some-college|           6208.0|              10.0|               15.0| 475.9207920792079|\n",
      "|            Divorced|      Assoc-voc|          14690.0|              11.0|                3.0|  494.243553008596|\n",
      "|            Divorced|           11th|           7954.0|               7.0|                1.0|213.94767441860466|\n",
      "|            Divorced|           10th|           2974.0|               6.0|                1.0| 94.36842105263158|\n",
      "|       Never-married|           10th|          24292.0|               6.0|                3.0|108.32420091324201|\n",
      "|  Married-civ-spouse|     Assoc-acdm|          90945.0|              12.0|                4.0| 864.8827067669173|\n",
      "|           Separated|      Doctorate|           1408.0|              16.0|               10.0|1494.3636363636363|\n",
      "|             Widowed|            9th|           2231.0|               5.0|                5.0| 73.64285714285714|\n",
      "|            Divorced|        7th-8th|           7872.0|               4.0|               16.0| 61.19047619047619|\n",
      "|           Separated|      Bachelors|           8616.0|              13.0|                7.0|2321.4651162790697|\n",
      "|             Widowed|      Assoc-voc|           3004.0|              11.0|                8.0|            1539.5|\n",
      "|             Widowed|           10th|          10368.0|               6.0|                6.0| 43.47540983606557|\n",
      "|             Widowed|      Doctorate|           2472.0|              16.0|                6.0| 4939.833333333333|\n",
      "|  Married-civ-spouse|      Preschool|           1672.0|               1.0|               24.0|1909.0833333333333|\n",
      "|           Separated|      Assoc-voc|           4034.0|              11.0|               20.0|            123.85|\n",
      "|Married-spouse-ab...|      Doctorate|              0.0|              16.0|                4.0|            5896.0|\n",
      "|            Divorced|      Preschool|              0.0|               1.0|               40.0|               0.0|\n",
      "|  Married-civ-spouse|        Masters|         306374.0|              14.0|                2.0|3219.0208623087624|\n",
      "|           Separated|     Assoc-acdm|           1408.0|              12.0|                3.0|  924.829268292683|\n",
      "+--------------------+---------------+-----------------+------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dicMulti = {\n",
    "    \"education-num\" : \"min\",\n",
    "    \"education-num\" : \"max\",\n",
    "    \"capital-gain\" : \"avg\",\n",
    "    \"capital-loss\" : \"sum\",\n",
    "    \"hours-per-week\" : \"min\"\n",
    "}\n",
    "\n",
    "dfCensus.groupby('marital-status','education_level').agg(dicMulti).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing, you would notice in the above code, that two operations on the same column as a separate dictionary entry does not work. Of the \"sum\" and \"avg\" operation on the column \"income\", the latter \"avg\" replaces the former \"sum\", while producing the output dataframe. \n",
    "\n",
    "You cannot achieve the desired output via dictionaries. You would have to use sql functions available under sql package instead, as demonstrated in the code below. The below code also shows multiple aggregations being done using Spark SQL aggregate functions in a single line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+------------------+------------------+------------------+-----------------+-------------------+\n",
      "|      marital-status|education_level|min(education-num)|max(education-num)| avg(capital-gain)|sum(capital-loss)|min(hours-per-week)|\n",
      "+--------------------+---------------+------------------+------------------+------------------+-----------------+-------------------+\n",
      "|             Widowed|   Some-college|              10.0|              10.0| 350.8256880733945|          12312.0|                1.0|\n",
      "|Married-spouse-ab...|   Some-college|              10.0|              10.0| 475.9207920792079|           6208.0|               15.0|\n",
      "|            Divorced|      Assoc-voc|              11.0|              11.0|  494.243553008596|          14690.0|                3.0|\n",
      "|            Divorced|           11th|               7.0|               7.0|213.94767441860466|           7954.0|                1.0|\n",
      "|            Divorced|           10th|               6.0|               6.0| 94.36842105263158|           2974.0|                1.0|\n",
      "|       Never-married|           10th|               6.0|               6.0|108.32420091324201|          24292.0|                3.0|\n",
      "|  Married-civ-spouse|     Assoc-acdm|              12.0|              12.0| 864.8827067669173|          90945.0|                4.0|\n",
      "|           Separated|      Doctorate|              16.0|              16.0|1494.3636363636363|           1408.0|               10.0|\n",
      "|             Widowed|            9th|               5.0|               5.0| 73.64285714285714|           2231.0|                5.0|\n",
      "|            Divorced|        7th-8th|               4.0|               4.0| 61.19047619047619|           7872.0|               16.0|\n",
      "|           Separated|      Bachelors|              13.0|              13.0|2321.4651162790697|           8616.0|                7.0|\n",
      "|             Widowed|      Assoc-voc|              11.0|              11.0|            1539.5|           3004.0|                8.0|\n",
      "|             Widowed|           10th|               6.0|               6.0| 43.47540983606557|          10368.0|                6.0|\n",
      "|             Widowed|      Doctorate|              16.0|              16.0| 4939.833333333333|           2472.0|                6.0|\n",
      "|  Married-civ-spouse|      Preschool|               1.0|               1.0|1909.0833333333333|           1672.0|               24.0|\n",
      "|           Separated|      Assoc-voc|              11.0|              11.0|            123.85|           4034.0|               20.0|\n",
      "|Married-spouse-ab...|      Doctorate|              16.0|              16.0|            5896.0|              0.0|                4.0|\n",
      "|            Divorced|      Preschool|               1.0|               1.0|               0.0|              0.0|               40.0|\n",
      "|  Married-civ-spouse|        Masters|              14.0|              14.0|3219.0208623087624|         306374.0|                2.0|\n",
      "|           Separated|     Assoc-acdm|              12.0|              12.0|  924.829268292683|           1408.0|                3.0|\n",
      "+--------------------+---------------+------------------+------------------+------------------+-----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "dfCensus.groupby('marital-status','education_level').agg(\n",
    "        F.min(\"education-num\"),\n",
    "        F.max(\"education-num\"),\n",
    "        F.avg(\"capital-gain\"),\n",
    "        F.sum(\"capital-loss\"),\n",
    "        F.min(\"hours-per-week\")\n",
    "        ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue in the above examples, is that the output columns are in the form - aggregation_function(column_name), which is not intuitive for future dataframe operations. \n",
    "\n",
    "We would discuss three ways to rename a column with agg opertion in PySpark. But first the intuitive way of using the alias function, which would not work, as demonstrated below. It would not give an error though. The reason the below syntax does not work is because we are aliasing the whole dataframe instead of the column - max('education-num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status|max(education-num)|\n",
      "+--------------------+------------------+\n",
      "|           Separated|              16.0|\n",
      "|       Never-married|              16.0|\n",
      "|Married-spouse-ab...|              16.0|\n",
      "|            Divorced|              16.0|\n",
      "|             Widowed|              16.0|\n",
      "|   Married-AF-spouse|              16.0|\n",
      "|  Married-civ-spouse|              16.0|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The following code would work but would not rename the column. \n",
    "dfCensus.groupBy(\"marital-status\").max('education-num').alias('max_education_num').show()\n",
    "\n",
    "#max(\"education-num\", \"capital-gain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg_education_num|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 9.369241672572644|\n",
      "|       Never-married|10.017468146321415|\n",
      "|Married-spouse-ab...| 9.289855072463768|\n",
      "|            Divorced|10.096077497220898|\n",
      "|             Widowed| 9.149569303054033|\n",
      "|   Married-AF-spouse|              10.5|\n",
      "|  Married-civ-spouse|10.325290904773214|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 1\n",
    "# Remember we have used alias F while importing from pyspark.sql import functions\n",
    "# would not recommend - as you see, you have to select the all the column names, better would be Option 3.\n",
    "dfCensus.groupBy(\"marital-status\") \\\n",
    "         .avg('education-num') \\\n",
    "         .select(F.col(\"marital-status\"),\n",
    "                 F.col('avg(education-num)').alias('avg_education_num')) \\\n",
    "         .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-----------------+------------------+\n",
      "|      marital-status|education_level|max_education_num|  avg_capital_gain|\n",
      "+--------------------+---------------+-----------------+------------------+\n",
      "|             Widowed|   Some-college|             10.0| 350.8256880733945|\n",
      "|Married-spouse-ab...|   Some-college|             10.0| 475.9207920792079|\n",
      "|            Divorced|      Assoc-voc|             11.0|  494.243553008596|\n",
      "|            Divorced|           11th|              7.0|213.94767441860466|\n",
      "|            Divorced|           10th|              6.0| 94.36842105263158|\n",
      "|       Never-married|           10th|              6.0|108.32420091324201|\n",
      "|  Married-civ-spouse|     Assoc-acdm|             12.0| 864.8827067669173|\n",
      "|           Separated|      Doctorate|             16.0|1494.3636363636363|\n",
      "|             Widowed|            9th|              5.0| 73.64285714285714|\n",
      "|            Divorced|        7th-8th|              4.0| 61.19047619047619|\n",
      "|           Separated|      Bachelors|             13.0|2321.4651162790697|\n",
      "|             Widowed|      Assoc-voc|             11.0|            1539.5|\n",
      "|             Widowed|           10th|              6.0| 43.47540983606557|\n",
      "|             Widowed|      Doctorate|             16.0| 4939.833333333333|\n",
      "|  Married-civ-spouse|      Preschool|              1.0|1909.0833333333333|\n",
      "|           Separated|      Assoc-voc|             11.0|            123.85|\n",
      "|Married-spouse-ab...|      Doctorate|             16.0|            5896.0|\n",
      "|            Divorced|      Preschool|              1.0|               0.0|\n",
      "|  Married-civ-spouse|        Masters|             14.0|3219.0208623087624|\n",
      "|           Separated|     Assoc-acdm|             12.0|  924.829268292683|\n",
      "+--------------------+---------------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 2\n",
    "# use \"agg\" method instead of calling the aggregation function directly\n",
    "dfCensus.groupby('marital-status','education_level').agg(\n",
    "        F.max(\"education-num\").alias(\"max_education_num\"),\n",
    "        F.avg(\"capital-gain\").alias(\"avg_capital_gain\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg_education_num|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 9.369241672572644|\n",
      "|       Never-married|10.017468146321415|\n",
      "|Married-spouse-ab...| 9.289855072463768|\n",
      "|            Divorced|10.096077497220898|\n",
      "|             Widowed| 9.149569303054033|\n",
      "|   Married-AF-spouse|              10.5|\n",
      "|  Married-civ-spouse|10.325290904773214|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Option 3\n",
    "# using \"withColumnRenamed\"\n",
    "dfCensus.groupBy(\"marital-status\") \\\n",
    "         .avg('education-num') \\\n",
    "         .withColumnRenamed('avg(education-num)', 'avg_education_num') \\\n",
    "         .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoough Option 1 is covered for sake of completeness, we would recommend use of either Option 2 or Option 3.\n",
    "\n",
    "We have seen introduction to PySpark aggregations and groupBys. The real power of PySpark lies in how these are use in combination with other functions of Spark. (we use functions and methods interchangeably)\n",
    "\n",
    "For example, what if you want to have an aggregation based on a specific filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------+\n",
      "|marital-status|avg(capital-gain)|\n",
      "+--------------+-----------------+\n",
      "| Never-married|402.4831483764899|\n",
      "+--------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfCensus.groupby('marital-status') \\\n",
    "        .agg({'capital-gain': 'avg'}) \\\n",
    "        .where(F.col('marital-status') == 'Never-married') \\\n",
    "        .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that, you have applied filter on \"marital-status\", can you apply filter on \"age\"? No. \n",
    "\n",
    "Check out the error in the below code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You cannot appply filter on \"age\"\n",
    "dfCensus.groupby('marital-status') \\\n",
    "        .agg({'capital-gain': 'avg'}) \\\n",
    "        .where(F.col('age') >= 24) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the above code, you would get an error as follows - \n",
    "\n",
    "<span style=\"color:red;\">AnalysisException: \"cannot resolve '`age`' given input columns: [marital-status, avg(capital-gain)];;\\n'Filter ('age >= 24)\\n+- Aggregate [marital-status#14], [marital-status#14, avg(capital-gain#19) AS avg(capital-gain)#2563]\\n   +- Relation[age#10,workclass#11,education_level#12,education-num#13,marital-status#14,occupation#15,relationship#16,race#17,sex#18,capital-gain#19,capital-loss#20,hours-per-week#21,native-country#22,income#23] csv\\n\"</span>\n",
    "\n",
    "Here when we are using method chaining, it is not dfCensus which is available to all methods, but output of grouby() which is a GroupedData object containing the columns \"marital-status\" and \"avg(capital-gain)\" are passed to the where clause. \n",
    "\n",
    "Thus the columns specified in the groupBy and the agg, are available for filter operations. Read the above error, you cannot apply the filter on the column used for aggregation, but you can apply the filter on the aggregated column output as demonstrated below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|    marital-status| avg(capital-gain)|\n",
      "+------------------+------------------+\n",
      "| Married-AF-spouse|        3353.03125|\n",
      "|Married-civ-spouse|1736.5056281168368|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You cannot appply filter on \"age\" but only on columns returned by GroupedData object\n",
    "dfCensus.groupby('marital-status') \\\n",
    "        .agg({'capital-gain': 'avg'}) \\\n",
    "        .where(F.col('avg(capital-gain)') >= 1000) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what if you want to fire the groupBy on the subset. One of the approach is to apply filter() first and then pass the subset to the groupBy method.\n",
    "\n",
    "In the next two lines of code, compare the output of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 649.4770710059172|\n",
      "|       Never-married| 557.2544247787611|\n",
      "|Married-spouse-ab...| 708.4291262135922|\n",
      "|            Divorced|  834.120875583454|\n",
      "|             Widowed| 647.5765907305578|\n",
      "|   Married-AF-spouse| 3973.962962962963|\n",
      "|  Married-civ-spouse|1769.0337955779673|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You cannot appply filter on \"age\"\n",
    "dfCensus.filter(\"age>=24\") \\\n",
    "        .groupby('marital-status') \\\n",
    "        .agg({'capital-gain': 'avg'}) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to pass the filters in the aggregate clause, which even after applying groupBy the main dataframe is available for application of filters.\n",
    "\n",
    "Check out the code below and compare it with the previous output - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------------------------------+\n",
      "|      marital-status|avg(CASE WHEN (age >= 24) THEN capital-gain END)|\n",
      "+--------------------+------------------------------------------------+\n",
      "|           Separated|                               649.4770710059172|\n",
      "|       Never-married|                               557.2544247787611|\n",
      "|Married-spouse-ab...|                               708.4291262135922|\n",
      "|            Divorced|                                834.120875583454|\n",
      "|             Widowed|                               647.5765907305578|\n",
      "|   Married-AF-spouse|                               3973.962962962963|\n",
      "|  Married-civ-spouse|                              1769.0337955779673|\n",
      "+--------------------+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# While you cannot appply filter on \"age\" in the error code a few steps above, this works well perfectly\n",
    "dfCensus.groupby('marital-status') \\\n",
    "        .agg(\n",
    "            F.avg(\n",
    "                F.when(F.col('age')>=24,\n",
    "                F.col('capital-gain'))\n",
    "            )).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 623.0673281360737|\n",
      "|       Never-married| 402.4831483764899|\n",
      "|Married-spouse-ab...| 660.9438405797101|\n",
      "|            Divorced| 825.1003652532952|\n",
      "|             Widowed| 645.5481597494127|\n",
      "|   Married-AF-spouse|        3353.03125|\n",
      "|  Married-civ-spouse|1736.5056281168368|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Just a sanity check to see the output without any filters\n",
    "dfCensus.groupby('marital-status') \\\n",
    "        .agg({'capital-gain': 'avg'}) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which approach to use - using sql functions or the Spark methods. Depends on your comfort level, but cleaner and readable - the better. You got a strange column name when you used the \"when\" method (filter is not a method available in PySpark SQL package), we can use alias to rename the output as demonstrated below.\n",
    "\n",
    "While we would be covering using all the methods in combination to perform complex operation, in the chapter - Bringing it together, where you would see many such examples, here is a little taste of what one can expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSomeOutput = dfCensus.groupby('marital-status') \\\n",
    "    .agg( \\\n",
    "            F.sum(  \\\n",
    "                F.when( \\\n",
    "                        F.trim(F.col('marital-status')).isin( \\\n",
    "                            [\"Separated\", \"Divorced\", \"Widowed\"] \\\n",
    "                        ), \\\n",
    "                        F.col(\"capital-gain\"), \n",
    "                    ).otherwise(0) \\\n",
    "            ).alias(\"capital_gain_total\"), \\\n",
    "            F.count(\"marital-status\").alias(\"total_count\"), \\\n",
    "        ) \\\n",
    ".withColumn( \\\n",
    "    \"some_ratio\", F.col(\"capital_gain_total\") / F.col(\"total_count\") \\\n",
    ") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----------+-----------------+\n",
      "|      marital-status|capital_gain_total|total_count|       some_ratio|\n",
      "+--------------------+------------------+-----------+-----------------+\n",
      "|           Separated|          879148.0|       1411|623.0673281360737|\n",
      "|       Never-married|               0.0|      14598|              0.0|\n",
      "|Married-spouse-ab...|               0.0|        552|              0.0|\n",
      "|            Divorced|         5195657.0|       6297|825.1003652532952|\n",
      "|             Widowed|          824365.0|       1277|645.5481597494127|\n",
      "|   Married-AF-spouse|               0.0|         32|              0.0|\n",
      "|  Married-civ-spouse|               0.0|      21055|              0.0|\n",
      "+--------------------+------------------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSomeOutput.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This conclude our recipe on GroupBys and aggregations, which we have covered here in more detail. However GroupBys and Joins causes reshuffle, and movement of the data across the nodes, and can impact your Spark code processing time. \n",
    "\n",
    "We would discuss the approaches in detail in our Chapter - Optimizing Spark. Till then, let us move to our next notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
